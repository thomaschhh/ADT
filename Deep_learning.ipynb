{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python >= 3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn >= 0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "    !pip install -q -U tfx==0.21.2\n",
    "    print(\"You can safely ignore the package incompatibility errors.\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# TensorFlow >= 2.0 is required\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import os\n",
    "import glob\n",
    "import tqdm\n",
    "import json\n",
    "import librosa\n",
    "from librosa import display\n",
    "from pathlib import Path\n",
    "import IPython.display as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.ndimage.filters import maximum_filter1d\n",
    "from copy import deepcopy\n",
    "import joblib\n",
    "import csv\n",
    "from madmom.io import midi  # to get ground truth\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print 4 random wave files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fps = glob.glob('/Volumes/Ext_SSD/e-gmd-v1.0.0/**/*.wav', recursive=True)\n",
    "fps_random = []\n",
    "np.random.seed()\n",
    "\n",
    "# setup subplot \n",
    "nrows, ncols = 2, 2\n",
    "fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=(16, 6))\n",
    "\n",
    "# plot some audio waveforms\n",
    "for r in range(nrows):\n",
    "    for c in range(ncols):\n",
    "        fp_random = fps[np.random.randint(len(fps))]\n",
    "        audio, sr = librosa.core.load(fp_random, duration=1,sr=None)\n",
    "        ax[r][c].plot(audio, c='k')\n",
    "        # ax[r][c].axis('off')\n",
    "        ax[r][c].set_title(Path(fp_random).parts[-2:])\n",
    "        if r == 0:\n",
    "            ax[r][c].set_xticks([])\n",
    "        # save random audio filepaths\n",
    "        fps_random.append(fp_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define config file for mel spectogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best-practice: write down your preprocessing config in a dictonary\n",
    "config = {'sr': 16000, \n",
    "          'audio_length': 1,  # in seconds\n",
    "          'mono': True,\n",
    "          'n_mels': 64,  # number bins / vertical resolution\n",
    "          'n_fft': 2048,  # samples for fft\n",
    "          'hop_length': 441, # shift to the right / frames with 10ms width\n",
    "          'win_length': 2048,\n",
    "          'window': 'hann',\n",
    "          'center': True,\n",
    "          'pad_mode': 'reflect',\n",
    "          'power': 2.0,\n",
    "         }\n",
    "\n",
    "# save number of frames from length in samples divided by fft hop length\n",
    "config['n_frames'] = int(config['sr']*config['audio_length']/config['hop_length']) + 1\n",
    "print(f'config[\"n_frames\"]: {config[\"n_frames\"]}')\n",
    "\n",
    "# save input shape for model\n",
    "config['input_shape'] = (config['n_frames'], config['n_mels'],  1)\n",
    "print(f'config[\"input_shape\"]: {config[\"input_shape\"]}')\n",
    "\n",
    "# save config \n",
    "with open('/Volumes/Ext_SSD/e-gmd-v1.0.0/e-gmd.json', 'w+') as fp:\n",
    "    json.dump(config, fp, sort_keys=True, indent=4)\n",
    "\n",
    "# pretty print json\n",
    "print(json.dumps(config, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STFTs / Mel Spectograms of the 4 randomly chosen wav files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# setup subplot \n",
    "nrows, ncols = 4, 2\n",
    "fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=(16, 12))\n",
    "\n",
    "# plot some audio waveforms\n",
    "for i, fp_random in enumerate(fps_random):\n",
    "    audio, sr = librosa.core.load(fp_random, duration=1,sr=config['sr'])\n",
    "\n",
    "    # calculate stft\n",
    "    stft = librosa.stft(audio, n_fft=config['n_fft'], hop_length=config['hop_length'], win_length=config['win_length'])\n",
    "    \n",
    "    # calculate melspec\n",
    "    melspec = librosa.feature.melspectrogram(audio, n_fft=config['n_fft'], hop_length=config['hop_length'], win_length=config['win_length'], n_mels=config['n_mels'], fmax=int(config['sr']/2))\n",
    "    melspec = librosa.amplitude_to_db(melspec, ref=np.max)\n",
    "\n",
    "    # calculate magnitude and scale to dB\n",
    "    magspec = librosa.amplitude_to_db(np.abs(stft), ref=np.max)\n",
    "\n",
    "    # plot with librosa\n",
    "    librosa.display.specshow(magspec, x_axis='time', y_axis='linear', sr=config['sr'], hop_length=config['hop_length'], ax=ax[i][0])\n",
    "    librosa.display.specshow(melspec, x_axis='time', y_axis='mel', sr=config['sr'], hop_length=config['hop_length'], ax=ax[i][1])\n",
    "    \n",
    "    # adjustments\n",
    "    # ax[i][1].set_yticks([])\n",
    "    ax[i][1].set_ylabel(Path(fp_random).parts[-2], rotation=270, labelpad=20)\n",
    "    ax[i][1].yaxis.set_label_position(\"right\")\n",
    "    \n",
    "    # settings for all axises but bottom ones\n",
    "    if not i == len(fps_random) - 1:\n",
    "        ax[i][0].set_xticks([])\n",
    "        ax[i][1].set_xticks([])\n",
    "        ax[i][0].set_xlabel('')\n",
    "        ax[i][1].set_xlabel('')\n",
    "    \n",
    "    # settings for upper axises\n",
    "    if i == 0:\n",
    "        ax[i][0].set_title('stft')\n",
    "        ax[i][1].set_title('mel spectrogram')   \n",
    "\n",
    "# adjust whitespace in between subplots        \n",
    "plt.subplots_adjust(hspace=0.1, wspace=0.1)\n",
    "\n",
    "print('Melspec shape: %s' % (str(melspec.shape)))\n",
    "print('Stft shape: %s' % (str(stft.shape)))\n",
    "print(f'Total data points in mel-spectrogram: {melspec.shape[0]*melspec.shape[1]}')\n",
    "print(f'Total data points in stft-spectrogram: {stft.shape[0]*stft.shape[1]}')\n",
    "print(f'-> Data Reduction by factor: {(stft.shape[0]*stft.shape[1]) / (melspec.shape[0]*melspec.shape[1])}')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ground truth mapping of MIDI notes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drum_mapping={\n",
    "          36: 0, #kick\n",
    "          38: 1, #snare head\n",
    "          40: 2, #snare rim\n",
    "          37: 3, #snare x-stick\n",
    "          48: 4, #tom1\n",
    "          50: 5, #tom1_rim\n",
    "          45: 6, #tom2\n",
    "          47: 7, #tom2_rim\n",
    "          43: 8, #tom3_head\n",
    "          58: 9, #tom3_rim\n",
    "          46: 10,#hhopen_bow\n",
    "          26: 11,#hhopen_edge\n",
    "          42: 12,#hhclosed_bow\n",
    "          \n",
    "          22: 13,#hhclosed_edge\n",
    "          44: 14,#hhpedal\n",
    "          49: 15,#crash1_bow\n",
    "          55: 16,#crash1_edge\n",
    "          57: 17,#crash2_bow\n",
    "          52: 18,#crash2_edge\n",
    "          51: 19,#ride_bow          \n",
    "          59: 20,#ride_edge\n",
    "          53: 21,#ride_bell\n",
    "          \n",
    "          39: 22,#clap\n",
    "          54: 23,#tambourine\n",
    "          56: 24,#cowbell\n",
    "          70: 25,#maracas\n",
    "          64: 26,#low_conga\n",
    "          75: 27 #claves\n",
    "         }\n",
    "\n",
    "# save config \n",
    "with open('/Volumes/Ext_SSD/e-gmd-v1.0.0/e-gmd.json', 'w+') as fp:\n",
    "    json.dump(drum_mapping, fp, sort_keys=True, indent=4)\n",
    "\n",
    "# pretty print json\n",
    "print(json.dumps(drum_mapping, indent=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting ground thruth from MIDI file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y_from_file(midifile, n_frames):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore')\n",
    "        pattern = midi.MIDIFile(midifile)\n",
    "        dt = float(config['hop_length']) / float(config['sr'])       \n",
    "        \n",
    "        y_onsets = np.zeros((n_frames, len(drum_mapping)), dtype=np.uint8) #28 instruments deswegen 28-1 \n",
    "        \n",
    "        i=0\n",
    "        for note in pattern.notes:\n",
    "            instrument=int(note[1])  #1st value in array is for instrument type\n",
    "            label=drum_mapping[instrument]\n",
    "\n",
    "            note_start = int(np.round(note[0] / dt)) # 0. value in array is the onset\n",
    "            i=i+1\n",
    "            \n",
    "            if note_start < n_frames:\n",
    "                y_onsets[note_start, label] = 1\n",
    "            \n",
    "            else:\n",
    "                print('Offset > n_frames reached')\n",
    "                break\n",
    "\n",
    "        return y_onsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print onset i[0], label i[1] or duration [2] here \n",
    "midi_file_path = glob.glob('/Volumes/Ext_SSD/e-gmd-v1.0.0/**/*.midi', recursive=True)\n",
    "pattern = midi.MIDIFile(midi_file_path[1])\n",
    "\n",
    "for i in pattern.notes:\n",
    "    if (i[0] >= config['audio_length']):\n",
    "        break\n",
    "    \n",
    "    print(i[1])\n",
    "    print(i[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define a mel filter matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_filter = librosa.filters.mel(config['sr'], \n",
    "                                 config['n_fft'], \n",
    "                                 n_mels=config['n_mels'], \n",
    "                                 fmin=0.0, \n",
    "                                 fmax=None, \n",
    "                                 htk=False, \n",
    "                                 norm='slaney', \n",
    "                                 dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(file_path):\n",
    "    # path string is saved as byte array in tf.data.dataset -> convert back to str\n",
    "    if type(file_path) is not str:\n",
    "        file_path = file_path.numpy()\n",
    "        file_path = file_path.decode('utf-8')\n",
    "    \n",
    "    \n",
    "    # load audio data \n",
    "    y, _ = librosa.core.load(file_path, sr=config['sr'], mono=config['mono'], offset=0.0, duration=None, \n",
    "                             dtype=np.float32, res_type='kaiser_best')\n",
    "\n",
    "    # calculate stft from audio data\n",
    "    stft = librosa.core.stft(y, n_fft=config['n_fft'], hop_length=config['hop_length'], \n",
    "                             win_length=config['win_length'], window=config['window'], \n",
    "                             center=config['center'], dtype=np.complex64, pad_mode=config['pad_mode'])\n",
    "\n",
    "    # filter stft with mel-filter\n",
    "    mel_spec = mel_filter.dot(np.abs(stft).astype(np.float32) ** config['power'])\n",
    "    \n",
    "    # add channel dimension for conv layer  compatibility\n",
    "    mel_spec = np.expand_dims(mel_spec, axis=-1)\n",
    "    \n",
    "    # get ground truth from file_path string\n",
    "    midi_file_path = file_path.replace(\"wav\", \"midi\")\n",
    "    ground_truth = get_y_from_file(midi_file_path, mel_spec.shape[1]) \n",
    "    \n",
    "    return mel_spec, ground_truth\n",
    "\n",
    "\n",
    "def preprocessing_wrapper(file_path):\n",
    "    mel_spec, ground_truth = tf.py_function(load_and_preprocess_data, [file_path], [tf.float32, tf.uint8])\n",
    "    \n",
    "    mel_spec = tf.transpose(mel_spec, perm=[1,0,2], conjugate=False, name='transpose')\n",
    "    mel_spec.set_shape([mel_spec.shape[0], config['n_mels'], 1])\n",
    "    \n",
    "    ground_truth.set_shape([mel_spec.shape[0], len(drum_mapping)])\n",
    "    \n",
    "    return mel_spec, ground_truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process One Test File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = glob.glob('/Volumes/Ext_SSD/e-gmd-v1.0.0/Train/*.wav', recursive=True)\n",
    "num_train_files = len(train_files)\n",
    "\n",
    "mel_spec, ground_truth = preprocessing_wrapper(train_files[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Datasets as tf record files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autotune computation\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "# Paths of train files\n",
    "train_files = glob.glob('/Volumes/Ext_SSD/e-gmd-v1.0.0/Train/*.wav', recursive=True)\n",
    "\n",
    "# Train dataset (file paths)\n",
    "train_dataset = tf.data.Dataset.list_files(train_files)\n",
    "\n",
    "# Preprocessing\n",
    "train_dataset = train_dataset.map(preprocessing_wrapper, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "# Slicing\n",
    "train_dataset = train_dataset.map(lambda spec, label: (tf.signal.frame(spec, config['n_frames'], config['n_frames'], axis=0), tf.signal.frame(label, config['n_frames'], config['n_frames'], axis=0)), num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "train_dataset = train_dataset.unbatch()  # slicing aufloesen, jedes Beispiel wird einzeln hintereinander \n",
    "\n",
    "# Save dataset to disk\n",
    "!rm -rf /Users/thomas/Documents/TU-Berlin/Faecher/Semester3/Audio_DeepLearning/ADT/TF_rec/tf_train\n",
    "tf.data.experimental.save(dataset=train_dataset,path=f'/Users/thomas/Documents/TU-Berlin/Faecher/Semester3/Audio_DeepLearning/ADT/TF_rec/tf_train', compression='GZIP')\n",
    "\n",
    "# Show tensor types and shapes in dataset\n",
    "print(f'train_dataset.element_spec:\\n {train_dataset.element_spec}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths of test files\n",
    "test_files = glob.glob('/Volumes/Ext_SSD/e-gmd-v1.0.0/Test/*.wav', recursive=True)\n",
    "\n",
    "# Test dataset (file paths)\n",
    "test_dataset = tf.data.Dataset.list_files(test_files)\n",
    "\n",
    "# Preprocessing \n",
    "test_dataset = test_dataset.map(preprocessing_wrapper, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "# Slicing\n",
    "test_dataset = test_dataset.map(lambda spec, label: (tf.signal.frame(spec, config['n_frames'], config['n_frames'], axis=0), tf.signal.frame(label, config['n_frames'], config['n_frames'], axis=0)), num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "test_dataset = test_dataset.unbatch()  # slicing aufloesen, jedes Beispiel wird einzeln hintereinander \n",
    "\n",
    "# Save dataset to disk\n",
    "!rm -rf /Users/thomas/Documents/TU-Berlin/Faecher/Semester3/Audio_DeepLearning/ADT/TF_rec/tf_test\n",
    "tf.data.experimental.save(dataset=test_dataset, path=f'/Users/thomas/Documents/TU-Berlin/Faecher/Semester3/Audio_DeepLearning/ADT/TF_rec/tf_test', compression='GZIP')\n",
    "\n",
    "# Show tensor types and shapes in dataset\n",
    "print(f'test_dataset.element_spec:\\n {test_dataset.element_spec}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Datasets from Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train dataset\n",
    "train_dataset = tf.data.experimental.load(f'/Users/thomas/Documents/TU-Berlin/Faecher/Semester3/Audio_DeepLearning/ADT/TF_rec/tf_train', \n",
    "                                    (tf.TensorSpec(shape=(config['n_frames'], config['n_mels'], 1), dtype=tf.float32, name=None), \n",
    "                                     tf.TensorSpec(shape=(config['n_frames'], len(drum_mapping)), dtype=tf.uint8, name=None)), \n",
    "                                    compression='GZIP')\n",
    "# Keep dataset in memory\n",
    "train_dataset = train_dataset.cache()\n",
    "\n",
    "# Shuffle the data\n",
    "train_dataset = train_dataset.shuffle(buffer_size=num_train_files)\n",
    "\n",
    "# Batch examples\n",
    "train_dataset = train_dataset.batch(64)\n",
    "\n",
    "# Prefetch\n",
    "train_dataset = train_dataset.prefetch(AUTOTUNE)\n",
    "\n",
    "# Test Dataset\n",
    "test_dataset = tf.data.experimental.load(f'/Users/thomas/Documents/TU-Berlin/Faecher/Semester3/Audio_DeepLearning/ADT/TF_rec/tf_test', \n",
    "                                    (tf.TensorSpec(shape=(config['n_frames'], config['n_mels'], 1), dtype=tf.float32, name=None), \n",
    "                                     tf.TensorSpec(shape=(config['n_frames'], len(drum_mapping)), dtype=tf.uint8, name=None)), \n",
    "                                    compression='GZIP')\n",
    "\n",
    "# Keep dataset in memory\n",
    "test_dataset = test_dataset.cache()\n",
    "\n",
    "# Batch examples\n",
    "test_dataset = test_dataset.batch(64)\n",
    "\n",
    "# Prefetch\n",
    "test_dataset = test_dataset.prefetch(AUTOTUNE)\n",
    "\n",
    "# Show tensor types and shapes in dataset \n",
    "print(f'train_dataset.element_spec:\\n {train_dataset.element_spec}')\n",
    "print(f'test_dataset.element_spec:\\n {test_dataset.element_spec}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model: Compile & Fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.Input(shape=config['input_shape']))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Conv2D(32, (3, 3), activation=\"relu\", padding='same'))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(1, 2)))\n",
    "model.add(tf.keras.layers.GaussianDropout(0.25))\n",
    "model.add(tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\", padding='same'))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(1, 2)))\n",
    "model.add(tf.keras.layers.GaussianDropout(0.25))\n",
    "model.add(tf.keras.layers.Conv2D(28, (3, 3), activation=\"relu\", padding='same'))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(1, 16)))\n",
    "model.add(tf.keras.layers.Reshape((37,-1)))\n",
    "model.add(tf.keras.layers.Dense(28, activation=\"sigmoid\"))  \n",
    "model.summary()\n",
    "\n",
    "# List of metrics\n",
    "metrics = [tf.keras.metrics.BinaryAccuracy(),\n",
    "           tf.keras.metrics.TrueNegatives(),\n",
    "           tf.keras.metrics.TruePositives(),\n",
    "           tf.keras.metrics.FalseNegatives(),\n",
    "           tf.keras.metrics.FalsePositives(),\n",
    "           tf.keras.metrics.Precision(),\n",
    "           tf.keras.metrics.Recall(),\n",
    "          ]\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=metrics)\n",
    "\n",
    "# Fit model\n",
    "model.fit(train_dataset, epochs=20)\n",
    "\n",
    "# Test model\n",
    "model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN + BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "model_onset = tf.keras.Sequential()\n",
    "model_onset.add(tf.keras.Input(shape=config['input_shape']))\n",
    "model_onset.add(tf.keras.layers.Conv2D(16, (3, 3),activation=\"relu\", padding='same', name='2.'))\n",
    "model_onset.add(tf.keras.layers.BatchNormalization())\n",
    "model_onset.add(tf.keras.layers.Conv2D(16, (3, 3), activation=\"relu\", padding='same'))\n",
    "model_onset.add(tf.keras.layers.BatchNormalization())\n",
    "model_onset.add(tf.keras.layers.MaxPool2D(pool_size=(1, 2)))\n",
    "model_onset.add(tf.keras.layers.GaussianDropout(0.75))\n",
    "model_onset.add(tf.keras.layers.Conv2D(32, (3, 3), activation=\"relu\", padding='same'))\n",
    "model_onset.add(tf.keras.layers.BatchNormalization())\n",
    "model_onset.add(tf.keras.layers.MaxPool2D(pool_size=(1, 2)))\n",
    "model_onset.add(tf.keras.layers.GaussianDropout(0.75))\n",
    "model_onset.add(tf.keras.layers.Conv2D(1, (1, 1), activation=\"relu\", padding='same'))\n",
    "model_onset.add(tf.keras.layers.Reshape((37,-1)))\n",
    "model_onset.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,dropout=0.5, return_sequences=True)))\n",
    "model_onset.add(tf.keras.layers.Dense(28, activation=\"sigmoid\"))  \n",
    "model_onset.summary()\n",
    "\n",
    "# List of metrics\n",
    "metrics = [tf.keras.metrics.BinaryAccuracy(),\n",
    "           tf.keras.metrics.TrueNegatives(),\n",
    "           tf.keras.metrics.TruePositives(),\n",
    "           tf.keras.metrics.FalseNegatives(),\n",
    "           tf.keras.metrics.FalsePositives(),\n",
    "           tf.keras.metrics.Precision(),\n",
    "           tf.keras.metrics.Recall(),\n",
    "          ]\n",
    "\n",
    "# Compile model\n",
    "model_onset.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=metrics)\n",
    "\n",
    "# Fit model\n",
    "model_onset.fit(train_dataset, epochs=20)\n",
    "\n",
    "# Test model\n",
    "model_onset.evaluate(test_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
